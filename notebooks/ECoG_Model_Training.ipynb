{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ECoG Foundation Model Training\n",
        "This is meant to be a minimal notebook which is capable of running model training with a free to use colab notebooks. Feel free to change this as you see fit for your experiments."
      ],
      "metadata": {
        "id": "RF_L32Ep5MZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repository.\n",
        "!git clone https://github.com/leoniekerken/ECoG-foundation-model.git"
      ],
      "metadata": {
        "id": "wVNKawOv7ZZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, go into the repo you just downloaded and change the hugging face user access token in the Makefile to your personal access token. If you don't want to do this everytime you could also upload the code to your personal drive and change the path_to_github_repo variable below, although then you risk your code being out of date."
      ],
      "metadata": {
        "id": "nGmF6wkX76eD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data.\n",
        "!cd ECoG-foundation-model && make download-data"
      ],
      "metadata": {
        "id": "cL5lxjV27x2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The local path to the github repo. Must be accessible from this notebook.\n",
        "# If you just run the code above this will work.\n",
        "path_to_github_repo = 'ECoG-foundation-model/'"
      ],
      "metadata": {
        "id": "tZqDS43m71Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Required pip installs.\n",
        "!pip install accelerate\n",
        "!pip install einops\n",
        "!pip install mne\n",
        "!pip install mne-bids\n",
        "!pip install pyEDFlib"
      ],
      "metadata": {
        "id": "fXoQK2neIr6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add import for ECoG code.\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.join(path_to_github_repo, 'ECoG-MAE'))\n",
        "\n",
        "# Other imports\n",
        "from dataclasses import dataclass\n",
        "from config import system_setup, model_setup\n",
        "from loader import dl_setup\n",
        "from train import train_model"
      ],
      "metadata": {
        "id": "kKJiJx1HFePP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up args for training.\n",
        "@dataclass\n",
        "class ArgObject:\n",
        "    # If 'batch' then will normalize data within a batch. If\n",
        "    norm: str = None\n",
        "    data_size: float = 0.0\n",
        "    # If true then convert data to power envelope by taking magnitude of Hilbert\n",
        "    # transform.\n",
        "    env: bool = False\n",
        "    # Frequency bands for filtering raw iEEG data.\n",
        "    bands: list[list[int]] = None\n",
        "    # Frequency to resample data to.\n",
        "    new_fs: int = 0\n",
        "    # Batch size to train with.\n",
        "    batch_size: int = 32\n",
        "    # Relative path to the dataset root directory.\n",
        "    dataset_path: str = None\n",
        "    # Proportion of data to have in training set. The rest will go to test set.\n",
        "    train_data_proportion: float = 0.9\n",
        "    # If true then use contrastive loss to train model. Currently not supported.\n",
        "    use_contrastive_loss: bool = False\n",
        "    # Prepend classification token to input if True. Always True if\n",
        "    # use_contrastive_loss is True.\n",
        "    use_cls_token: bool = False\n",
        "    # Number of seconds of data to use for a training example.\n",
        "    sample_length: int = 0\n",
        "    # TODO\n",
        "    patch_size: list[int] = None\n",
        "    # TODO\n",
        "    frame_patch_size: int = 0\n",
        "    # Proportion of tubes to mask out. See VideoMAE paper for details.\n",
        "    tube_mask_ratio: float = 0.5\n",
        "    # Proportion of\n",
        "    decoder_mask_ratio: float = 0\n",
        "    # Dimensionality of token embeddings.\n",
        "    dim: int = 512\n",
        "    # Dimensionality of feedforward network after attention layer.\n",
        "    mlp_dim: int = 512\n",
        "    # Learning rate for training. If 0 then uses Adam scheduler.\n",
        "    learning_rate: float = 0.0\n",
        "    # Number of epochs to train over data.\n",
        "    num_epochs: int = 0\n",
        "    # Name of training job. Will be used to save metrics.\n",
        "    job_name: str = None\n",
        "\n",
        "\n",
        "# TODO: test batch size of 64 to see if VRAM runs out.\n",
        "args_dict = {\n",
        "    'norm': 'batch',\n",
        "    'data_size': 1.0,\n",
        "    'env': True,\n",
        "    'new_fs': 20,\n",
        "    # Currently set to 9 because get_model_recon.py in metrics.py assumes that\n",
        "    # the batch size is at least 9.\n",
        "    # See https://github.com/leoniekerken/ECoG-foundation-model/issues/1 about\n",
        "    # maybe changing that. I'm not sure on the exact limits but I've managed to\n",
        "    # get a batch size of 32 to work but a batch size of 64 leads to crashes on\n",
        "    # the free tier T4 GPU.\n",
        "    'batch_size': 32,\n",
        "    'bands': [[4,8],[8,13],[13,30],[30,55],[70,200]],\n",
        "    'sample_length': 2,\n",
        "    'patch_size': [1, 2, 2],\n",
        "    'frame_patch_size': 4,\n",
        "    'tube_mask_ratio': 0.5,\n",
        "    'decoder_mask_ratio': 0.0,\n",
        "    'dim': 80,\n",
        "    'mlp_dim': 80,\n",
        "    'learning_rate': 0.0,\n",
        "    'num_epochs': 10,\n",
        "    'job_name': 'test_overfitting',\n",
        "    'dataset_path': 'ECoG-foundation-model/dataset',\n",
        "    'train_data_proportion': 0.5,\n",
        "}\n",
        "args = ArgObject(**args_dict)"
      ],
      "metadata": {
        "id": "AItQVYImGnWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accelerator, device, data_type, local_rank = system_setup()"
      ],
      "metadata": {
        "id": "NmnMkoO-Hj79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl, test_dl, num_train_samples = dl_setup(args)\n",
        "\n",
        "# If you want to run a more minimal training run you can uncomment the code\n",
        "# below to limit the number of samples accessible by each dataset. This is\n",
        "# currently inefficient though if you use few training batches because it will\n",
        "# do summaries frequently which takes more time than an individual training\n",
        "# step.\n",
        "# train_num_batches = 1\n",
        "# test_num_batches = 1\n",
        "\n",
        "# for dataset in train_dl.dataset.datasets:\n",
        "#   dataset.max_samples = args.batch_size * train_num_batches\n",
        "# # Can reuse same dataloader for test\n",
        "# test_dl = train_dl\n",
        "# # Or just limit test dataloader\n",
        "# # for dataset in test_dl.dataset.datasets:\n",
        "# #   dataset.max_samples = args.batch_size * test_num_batches\n",
        "\n",
        "# num_train_samples = args.batch_size * train_num_batches"
      ],
      "metadata": {
        "id": "lJo9nzuP4y1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The data is arranged in shape b*c*t*d*h*w, where\n",
        "# b = batch size,\n",
        "# c = freq bands,\n",
        "# t = number of datapoints within a sample (args.new_fs samples per second)\n",
        "# d = depth (currently 1)\n",
        "# h = height of grid (currently 8)\n",
        "# w = width of grid (currently 8)\n",
        "\n",
        "print(next(train_dl._get_iterator())['signal'].shape)"
      ],
      "metadata": {
        "id": "w6UCfwRrCxa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, optimizer, lr_scheduler, num_patches = model_setup(\n",
        "    args, device, num_train_samples\n",
        ")"
      ],
      "metadata": {
        "id": "NWXEcPHE4uQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(\n",
        "        args,\n",
        "        device,\n",
        "        model,\n",
        "        train_dl,\n",
        "        test_dl,\n",
        "        num_patches,\n",
        "        optimizer,\n",
        "        lr_scheduler,\n",
        "        accelerator,\n",
        "        data_type,\n",
        "        local_rank,\n",
        "    )"
      ],
      "metadata": {
        "id": "j8TWC7OzOkhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now view the results of the training in results/"
      ],
      "metadata": {
        "id": "ErfIKIbrLZ4b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Ioe5hdQUgzM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}